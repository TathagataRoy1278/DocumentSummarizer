{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "*numpy* - for managing arrays\n",
    "\n",
    "*scipy.stats* for pearson score(which can be implemented in code too)\n",
    "\n",
    "*bs4, requests* - scrapping the page whose summary is required\n",
    "\n",
    "*nltk* - for tokenizing and finding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "recquired_length = 0.25\n",
    "total_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for loading word embeddings\n",
    "\n",
    "**Chnage the veriable *vectors_location* to the location where you downloaded the file mentioned in README.md**\n",
    "\n",
    "This function reads the vectors and stores them in a dictionary with the word as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "def load_word_embeddings():\n",
    "    vectors_location = \"/media/tatan/A0A04E3AA04E16E6/word_vectors/glove.6B.100d.txt\"\n",
    "    f = open(vectors_location,encoding = 'utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling the function to load the embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_word_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Webpage text in variable *text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(\"https://towardsdatascience.com/how-to-build-a-data-science-portfolio-5f566517c79c\").text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "title = soup.find('title').text\n",
    "paras = soup.findAll('p')\n",
    "text = [i.text for i in paras if len(i.text)>70]\n",
    "text = \"\".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sentence tokens\n",
    "\n",
    "These will be later evaluated, if they are needed in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = sent_tokenize(text)\n",
    "total_length = len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for extracting Word vectors from the *sentence_tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(sentence):\n",
    "    sentence = remove_stopwords_and_punctuations(sentence)\n",
    "    word_vectors = []\n",
    "    for word in sentence.split():\n",
    "        try:\n",
    "            word_vectors.append(deepcopy(word_embeddings[word.lower()]))\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for averaging all the values in the vectors axis-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencevector_avg(word_vectors):\n",
    "    avg_vector = []\n",
    "    if len(word_vectors)!=0:\n",
    "        avg_vector = np.array([sum([vector[axis] for vector in word_vectors])/len(word_vectors) for axis in range(len(word_vectors[0]))])\n",
    "    else:\n",
    "        avg_vector = np.zeros((100,))\n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for averaging all the values in the vectors axis-wise(weigheted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentencevector_avg_weighted(word_vectors,tmp_vectors,weight):\n",
    "    for i in range(len(tmp_vectors)):\n",
    "        for j in range(len(tmp_vectors[0])):\n",
    "            tmp_vectors[i][j] = weight*tmp_vectors[i][j]\n",
    "    word_vectors+=tmp_vectors\n",
    "    avg_vector = []\n",
    "    if len(word_vectors)!=0:\n",
    "        avg_vector = np.array([sum([vector[axis] for vector in word_vectors])/len(word_vectors) for axis in range(len(word_vectors[0]))])\n",
    "    else:\n",
    "        avg_vector = np.zeros((100,))\n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function name self explanatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_punctuations(sen):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    sen = \" \".join(tokenizer.tokenize(sen))\n",
    "    new_vec = \" \".join([word for word in sen.split() if word not in stop_words])\n",
    "    return new_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part of the code\n",
    "\n",
    "For each token in the summary it averages the word vectors them it compares it to the title.\n",
    "\n",
    "If the pearson score of the sentence vector is grater than 0.1(to rule out any unnessacary introductory lines) and the average  of the vector calculated uptil now, it is added to the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummary(title,sentence_tokens):\n",
    "    summary = []\n",
    "    sumoftmps = 9\n",
    "    avg = 0\n",
    "    ctr = 1\n",
    "    title_vector = sentencevector_avg(get_word_vectors(title))\n",
    "    for sentence_token in sentence_tokens:\n",
    "        sentence_vector = []\n",
    "\n",
    "        sentence_vector = sentencevector_avg(get_word_vectors(sentence_token))\n",
    "        \n",
    "        tmp = pearsonr(sentence_vector,title_vector)[0]\n",
    "        sumoftmps+=tmp\n",
    "        avg = sumoftmps/ctr\n",
    "        ctr+=1\n",
    "        if(tmp>=avg and tmp>0.1):\n",
    "            summary.append((tmp,sentence_token))\n",
    "            title_vector = sentencevector_avg_weighted(get_word_vectors(title),get_word_vectors(sentence_token),0.5)\n",
    "            \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = [(i,s) for i,s in enumerate(getSummary(title,sentence_tokens))]\n",
    "summary.sort(key = lambda x: x[1][0], reverse = True)\n",
    "\n",
    "final_summary = sorted(summary[:int(recquired_length*total_length)],key = lambda x: x[0])\n",
    "\n",
    "summary = \"\"\n",
    "for i in final_summary:\n",
    "    summary+=i[1][1]+\"\\n\"\n",
    "print(summary,len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
